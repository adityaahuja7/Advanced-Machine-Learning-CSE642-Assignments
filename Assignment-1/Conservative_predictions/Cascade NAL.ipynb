{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVH3nOPYBNw0"
      },
      "source": [
        "# Assignment-1\n",
        "## Team: Aditya Ahuja (2020275), Deeptanshu Barman Chowdhuri (2020293)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro-XJmUCBNw3"
      },
      "source": [
        "##  Imports & Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NmATk9NBNw3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.calibration import calibration_curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spHzIt_dFTM6"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "device\n",
        "# device = \"cpu\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZCz-48ZBNw5"
      },
      "outputs": [],
      "source": [
        "Noise_0_dataframe = pd.read_csv(\"../Data/Assignment1/data_0_noise\")\n",
        "Noise_Low_dataframe = pd.read_csv(\"../Data/Assignment1/data_Low_noise\")\n",
        "Noise_High_dataframe = pd.read_csv(\"../Data/Assignment1/data_High_noise\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKrqVPONBNw5",
        "outputId": "d0be1b06-6d08-4b0a-8610-33229693d6dd"
      },
      "outputs": [],
      "source": [
        "class_index = list(Noise_0_dataframe[\"era\"].unique())\n",
        "class_index_noise = list(Noise_Low_dataframe[\"era\"].unique())\n",
        "class_index_t10v_noise = list(Noise_Low_dataframe[\"target_10_val\"].unique())\n",
        "\n",
        "def encode(value, class_index = class_index):\n",
        "    return class_index.index(value)\n",
        "\n",
        "def encode_noise(value, class_index = class_index_noise):\n",
        "    return class_index.index(value)\n",
        "\n",
        "def encode_noise_t10v(value, class_index = class_index_t10v_noise):\n",
        "    return class_index.index(value)\n",
        "\n",
        "\n",
        "Noise_0_dataframe[\"era\"] = Noise_0_dataframe[\"era\"].apply(encode)\n",
        "Noise_Low_dataframe[\"era\"] = Noise_Low_dataframe[\"era\"].apply(encode_noise)\n",
        "Noise_High_dataframe[\"era\"] = Noise_High_dataframe[\"era\"].apply(encode_noise)\n",
        "Noise_Low_dataframe[\"target_10_val\"] = Noise_Low_dataframe[\"target_10_val\"].apply(encode_noise_t10v)\n",
        "Noise_High_dataframe[\"target_10_val\"] = Noise_High_dataframe[\"target_10_val\"].apply(encode_noise_t10v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWFHHoWmBNw7"
      },
      "source": [
        "##  Cascade_Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NAL_MLP(torch.nn.Module):\n",
        "    def __init__(self, modules, hidden_dim, output_dim):\n",
        "        super(NAL_MLP, self).__init__()\n",
        "        modules = torch.nn.ModuleList([m for m in modules])\n",
        "        self.layers = torch.nn.Sequential(*modules)\n",
        "        self.att_layer = torch.nn.Linear(hidden_dim, 1)\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.lastlinear = torch.nn.Linear(hidden_dim, output_dim)\n",
        "        self.temperature = torch.nn.Parameter(torch.ones(1))\n",
        "        self.sigm = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        y_hat = self.lastlinear(x)\n",
        "        y_hat=y_hat/torch.abs(self.temperature)\n",
        "        y_hat = self.softmax(y_hat)\n",
        "        h = self.att_layer(x)\n",
        "        h = self.sigm(h)\n",
        "        return y_hat, h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgsVEXEjT7ub"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10,verbose=True):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_train_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_train_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_train_loss / len(train_loader)\n",
        "        train_accuracy = correct_train / total_train\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                running_val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total_val += labels.size(0)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = running_val_loss / len(val_loader)\n",
        "        val_accuracy = correct_val / total_val\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
        "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(1, num_epochs + 1), train_losses, label='Train')\n",
        "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train')\n",
        "    plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NALLoss(torch.nn.Module):\n",
        "    def __init__(self, reg, no_of_class=12):\n",
        "        super(NALLoss, self).__init__()\n",
        "        self.reg = reg\n",
        "        self.no_of_class = no_of_class\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        p = torch.Tensor(inputs[0]).to(device).t()\n",
        "\n",
        "        targets = torch.eye(self.no_of_class).to(device)[targets].t()\n",
        "        tou = torch.Tensor(inputs[1]).to(device)\n",
        "        tou = tou.t()\n",
        "\n",
        "        loss_a = torch.t(targets) @ torch.log(tou * (p - targets) + targets)\n",
        "        loss_b = self.reg * torch.log(tou)\n",
        "        loss_a = loss_a.diag().t()\n",
        "\n",
        "        loss = loss_a + loss_b\n",
        "\n",
        "        return -loss.mean()\n",
        "\n",
        "    def custom_p(p):\n",
        "        return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def expected_calibration_error(samples, true_labels, M=5):\n",
        "    samples=samples.to(device)\n",
        "    true_labels=true_labels.to(device)\n",
        "\n",
        "    # uniform binning approach with M number of bins\n",
        "    bin_boundaries = torch.linspace(0, 1, M + 1)\n",
        "    bin_lowers = bin_boundaries[:-1]\n",
        "    bin_uppers = bin_boundaries[1:]\n",
        "\n",
        "    # get max probability per sample i\n",
        "    confidences = torch.max(samples, dim=1)[0]\n",
        "    # get predictions from confidences (positional in this case)\n",
        "    predicted_label = torch.argmax(samples, dim=1)\n",
        "\n",
        "    # get a boolean list of correct/false predictions\n",
        "    accuracies = predicted_label == true_labels\n",
        "\n",
        "    ece = torch.zeros(1).to(device)\n",
        "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
        "        # determine if sample is in bin m (between bin lower & upper)\n",
        "        in_bin = torch.logical_and(confidences > bin_lower.item(), confidences <= bin_upper.item())\n",
        "        # can calculate the empirical probability of a sample falling into bin m: (|Bm|/n)\n",
        "        prob_in_bin = in_bin.float().mean()\n",
        "\n",
        "        if prob_in_bin.item() > 0:\n",
        "            # get the accuracy of bin m: acc(Bm)\n",
        "            accuracy_in_bin = accuracies[in_bin].float().mean()\n",
        "            # get the average confidence of bin m: conf(Bm)\n",
        "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
        "            # calculate |acc(Bm) - conf(Bm)| * (|Bm|/n) for bin m and add to the total ECE\n",
        "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prob_in_bin\n",
        "    return ece.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_with_calibration(model, criterion, optimizer, train_loader, val_loader, num_epochs=10, verbose=True):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_train_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            ece = expected_calibration_error(outputs[0], labels)\n",
        "            loss = criterion(outputs, labels) + ece\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_train_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs[0], 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_train_loss / len(train_loader)\n",
        "        train_accuracy = correct_train / total_train\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        if val_loader != None:\n",
        "            model.eval()\n",
        "            running_val_loss = 0.0\n",
        "            correct_val = 0\n",
        "            total_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    inputs, labels = inputs.to(device).to(torch.float32), labels.to(\n",
        "                        device\n",
        "                    ).to(torch.long)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    running_val_loss += loss.item()\n",
        "\n",
        "                    _, predicted = torch.max(outputs[0], 1)\n",
        "                    total_val += labels.size(0)\n",
        "                    correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loss = running_val_loss / len(val_loader)\n",
        "            val_accuracy = correct_val / total_val\n",
        "            val_losses.append(val_loss)\n",
        "            val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "            f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, \"\n",
        "        )\n",
        "\n",
        "    if val_loader != None:\n",
        "        plt.plot(range(1, num_epochs + 1), train_accuracies, label=\"Train\")\n",
        "        plt.plot(range(1, num_epochs + 1), val_accuracies, label=\"Validation\")\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.title(\"Training and Validation Accuracy\")\n",
        "        plt.legend()\n",
        "\n",
        "    else:\n",
        "        plt.plot(range(1, num_epochs + 1), train_accuracies, label=\"Train\")\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(\"Accuracy\")\n",
        "        plt.title(\"Training Accuracy\")\n",
        "        plt.legend()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_cascade(num_classes,initial_data,initial_label,impurity,level,epochs=3):\n",
        "    initial_data, initial_label = torch.from_numpy(initial_data).to(device), torch.from_numpy(initial_label).to(device)\n",
        "    Dataset  = torch.utils.data.TensorDataset(initial_data, initial_label)\n",
        "    D_loader = DataLoader(Dataset, batch_size=1024, shuffle=True)  \n",
        "    Models =[]\n",
        "    for lev in range(level):\n",
        "        level_total_correct = 0\n",
        "        level_total = 0\n",
        "        print(\"Current Level:\",lev)\n",
        "        modules = [torch.nn.Linear(24,64),torch.nn.ReLU(),torch.nn.Linear(64,128),torch.nn.ReLU(),torch.nn.Linear(128,64),torch.nn.ReLU()]\n",
        "        level_model = NAL_MLP(modules, hidden_dim=64,output_dim=num_classes).to(device)\n",
        "        level_model = level_model.to(device)\n",
        "        optimizer = torch.optim.Adam(level_model.parameters(), lr=0.004)\n",
        "        train_with_calibration(level_model,NALLoss(5,num_classes), optimizer,D_loader,None,num_epochs=epochs)\n",
        "        new_dataset=[]\n",
        "        new_labelset=[]\n",
        "        for inputs,labels in D_loader:\n",
        "            inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
        "            outputs = level_model(inputs)\n",
        "            softmaxed = outputs[0]\n",
        "            gini=softmaxed@softmaxed.T\n",
        "            gini=torch.diag(gini)\n",
        "            gini=1-gini\n",
        "            for i in range(len(gini)):\n",
        "                if gini[i]>impurity[lev]:\n",
        "                    new_dataset.append(inputs[i].cpu().detach().numpy())\n",
        "                    new_labelset.append(labels[i].cpu().detach().numpy())\n",
        "                else:\n",
        "                    _,pred = torch.max(softmaxed[i], 0)\n",
        "                    if pred == labels[i]:\n",
        "                        level_total_correct += 1\n",
        "                    level_total += 1\n",
        "        print(\"Level accuracy:\",level_total_correct/level_total)\n",
        "        print(\"Number of samples pruned:\",level_total)\n",
        "        print(\"For the next level, the number of samples is:\",len(new_dataset))\n",
        "        new_dataset, new_labelset = torch.from_numpy(np.array(new_dataset)), torch.from_numpy(np.array(new_labelset))\n",
        "        new_dataset = torch.utils.data.TensorDataset(new_dataset, new_labelset)\n",
        "        D_loader = DataLoader(new_dataset, batch_size=1024, shuffle=True)    \n",
        "        Models.append(level_model)\n",
        "    return Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#sample 80% of the train data \n",
        "train_data = Noise_High_dataframe \n",
        "train_data,test_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
        "num_classes = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = train_cascade(num_classes,train_data.iloc[:,:-6].values,train_data.loc[:,\"target_10_val\"].values,level = 4, impurity = [0.1,0.2,0.3,0.4],epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_cascade(models,initial_test_data,initial_test_labels,impurity):\n",
        "    for model in models:\n",
        "        model.eval()\n",
        "    testloader = DataLoader(torch.utils.data.TensorDataset(torch.from_numpy(initial_test_data).to(device), torch.from_numpy(initial_test_labels).to(device)), batch_size=1024, shuffle=True)\n",
        "    total_correct = 0\n",
        "    total_predicted = 0\n",
        "    for modelnum in range(len(models)):\n",
        "        correct_on_this_level = 0\n",
        "        total_on_this_level = 0\n",
        "        new_dataset=[]\n",
        "        new_labelset=[]\n",
        "        for inputs,labels in testloader:\n",
        "            inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
        "            outputs = models[modelnum](inputs)\n",
        "            softmaxed = outputs[0]\n",
        "            gini = softmaxed@softmaxed.T\n",
        "            gini = torch.diag(gini)\n",
        "            gini = 1-gini\n",
        "            for i in range(len(gini)):\n",
        "                if gini[i]>impurity[modelnum]:\n",
        "                    new_dataset.append(inputs[i].cpu().detach().numpy())\n",
        "                    new_labelset.append(labels[i].cpu().detach().numpy())\n",
        "                else:\n",
        "                    pred = torch.argmax(softmaxed[i])\n",
        "                    if (pred == labels[i]):\n",
        "                        total_correct += 1\n",
        "                        correct_on_this_level += 1\n",
        "                    total_on_this_level += 1\n",
        "                    total_predicted += 1\n",
        "            \n",
        "        if(total_on_this_level!=0): print(\"Accuracy at level-\",modelnum,\":\",correct_on_this_level/total_on_this_level)\n",
        "        new_dataset, new_labelset = torch.from_numpy(np.array(new_dataset)), torch.from_numpy(np.array(new_labelset))\n",
        "        print(\"For this level, the number of samples is:\",total_on_this_level)\n",
        "        new_dataset = torch.utils.data.TensorDataset(new_dataset, new_labelset)\n",
        "        if (len(new_dataset) == 0):\n",
        "            break\n",
        "        testloader = DataLoader(new_dataset, batch_size=1024, shuffle=True)\n",
        "    print(\"TOTAL PREDCITED:\",total_predicted)\n",
        "    print(\"TOTAL NOT PREDICTED:\",len(initial_test_data)-total_predicted)\n",
        "    print(\"FINAL ACCURACY:\",total_correct/total_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_cascade(models,test_data.iloc[:,:-6].values,test_data.loc[:,\"target_10_val\"].values,impurity = [0.1,0.2,0.3,0.4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Calibration Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def binarize(target, c):\n",
        "    return np.array([1 if t == c else 0 for t in target])\n",
        "\n",
        "def plot_calibration_curve(cls,models,initial_test_data,initial_test_labels,impurity):\n",
        "    for model in models:\n",
        "        model.eval()\n",
        "    testloader = DataLoader(torch.utils.data.TensorDataset(torch.from_numpy(initial_test_data).to(device), torch.from_numpy(initial_test_labels).to(device)), batch_size=1024, shuffle=True)\n",
        "    y_true = []\n",
        "    y_probabilities = []\n",
        "    for modelnum in range(len(models)):\n",
        "        new_dataset=[]\n",
        "        new_labelset=[]\n",
        "        for inputs,labels in testloader:\n",
        "            inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
        "            outputs = models[modelnum](inputs)\n",
        "            softmaxed = outputs[0]\n",
        "            gini = softmaxed@softmaxed.T\n",
        "            gini = torch.diag(gini)\n",
        "            gini = 1-gini\n",
        "            for i in range(len(gini)):\n",
        "                if gini[i]>impurity[modelnum]:\n",
        "                    new_dataset.append(inputs[i].cpu().detach().numpy())\n",
        "                    new_labelset.append(labels[i].cpu().detach().numpy())\n",
        "                else:\n",
        "                    y_true.append(labels[i].cpu().detach().numpy())\n",
        "                    y_probabilities.append(softmaxed[i][cls].detach().cpu().numpy())\n",
        "        new_dataset, new_labelset = torch.from_numpy(np.array(new_dataset)), torch.from_numpy(np.array(new_labelset))\n",
        "        new_dataset = torch.utils.data.TensorDataset(new_dataset, new_labelset)\n",
        "        if (len(new_dataset) == 0):\n",
        "            break\n",
        "        testloader = DataLoader(new_dataset, batch_size=1024, shuffle=True)\n",
        "\n",
        "    y_true_binarized = binarize(y_true, cls)\n",
        "\n",
        "    # print(len(y_true_binarized))\n",
        "    # print(len(y_probabilities))\n",
        "    # Calculate calibration curve\n",
        "    prob_true, prob_pred = calibration_curve(y_true_binarized,y_probabilities, n_bins=10)\n",
        "    print(prob_pred)\n",
        "    # Plot calibration curve\n",
        "    plt.plot(prob_pred, prob_true, marker='o', label=\"Class\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', label=\"Perfectly Calibrated\")\n",
        "    plt.xlabel(\"Confidence\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Calibration Curve\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cls=3\n",
        "plot_calibration_curve(cls,models,test_data.iloc[:,:-6].values,test_data.loc[:,\"target_10_val\"].values,impurity = [0.1,0.2,0.3,0.4])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c0de4b95e4545c0bbe9eafea153125b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd0232e4017240debb92efe3100b71a3",
              "IPY_MODEL_32fad7dacf594cb488bf6a261f933f8b",
              "IPY_MODEL_613424989e984c8888528d3a4d61a318"
            ],
            "layout": "IPY_MODEL_1ab03e476b624c699cc85fb8d9ec71a1"
          }
        },
        "1ab03e476b624c699cc85fb8d9ec71a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "2a39fbb734d74e8b9b9f44a0627b35a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32fad7dacf594cb488bf6a261f933f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2d642748e7c4d81a2ab1ec8d9720926",
            "max": 98,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5217d52572ba41ceba0130b5ac47af5b",
            "value": 98
          }
        },
        "3e901c104db34d8a88a632d8d897022b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5217d52572ba41ceba0130b5ac47af5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "613424989e984c8888528d3a4d61a318": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a39fbb734d74e8b9b9f44a0627b35a2",
            "placeholder": "​",
            "style": "IPY_MODEL_abbe93dc21094598aa884f59e3b4aaab",
            "value": " 98/98 [00:00&lt;00:00, 280.28it/s, v_num=3]"
          }
        },
        "95bf24f9ca0b4baab139e7716dffb754": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d642748e7c4d81a2ab1ec8d9720926": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abbe93dc21094598aa884f59e3b4aaab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd0232e4017240debb92efe3100b71a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95bf24f9ca0b4baab139e7716dffb754",
            "placeholder": "​",
            "style": "IPY_MODEL_3e901c104db34d8a88a632d8d897022b",
            "value": "Epoch 9: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
