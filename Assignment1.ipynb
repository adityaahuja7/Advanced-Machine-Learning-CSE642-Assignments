{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVH3nOPYBNw0"
      },
      "source": [
        "# Assignment-1\n",
        "## Team: Aditya Ahuja (2020275), Deeptanshu Barman Chowdhuri (2020293)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro-XJmUCBNw3"
      },
      "source": [
        "##  Imports & Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhU92hp7HylX",
        "outputId": "e8155f26-044e-407f-d786-9a09cbbb4e91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.3.0.post0-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.1 torchmetrics-1.3.0.post0\n",
            "Collecting lightning\n",
            "  Downloading lightning-2.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]<2025.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2023.6.0)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.10.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.23.5)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (23.2)\n",
            "Requirement already satisfied: torch<4.0,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.3.0.post0)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.9.0)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.2.0-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.3/800.3 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.8.0->lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=1.13.0->lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]<2025.0,>=2022.5.0->lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.13.0->lightning) (1.3.0)\n",
            "Installing collected packages: pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.2.0 pytorch-lightning-2.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "!pip install lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2NmATk9NBNw3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "import lightning as L\n",
        "import torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "spHzIt_dFTM6"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "# device = \"cpu\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXoJtlecBNw4"
      },
      "outputs": [],
      "source": [
        "Noise_0_data = requests.get(\n",
        "    \"http://AdityaAhuja01.pythonanywhere.com/data/df_syn_train_0_0_.csv\"\n",
        ")\n",
        "Noise_Low_data = requests.get(\n",
        "    \"http://AdityaAhuja01.pythonanywhere.com/data/df_synA_train_shuffled.csv\"\n",
        ")\n",
        "Noise_High_data = requests.get(\n",
        "    \"http://AdityaAhuja01.pythonanywhere.com/data/df_synA_test_hard_shuffled_sample.csv\"\n",
        ")\n",
        "\n",
        "if Noise_0_data.status_code == 200 and Noise_Low_data.status_code == 200 and Noise_High_data.status_code == 200:\n",
        "    datafolder = \"Data/Assignment1\"\n",
        "\n",
        "    if not os.path.exists(datafolder):\n",
        "        os.makedirs(datafolder)\n",
        "\n",
        "    with open(os.path.join(datafolder, \"data_0_noise\"), \"wb\") as f:\n",
        "        f.write(Noise_0_data.text.encode(\"utf-8\"))\n",
        "\n",
        "    with open(os.path.join(datafolder, \"data_Low_noise\"), \"wb\") as f:\n",
        "        f.write(Noise_Low_data.text.encode(\"utf-8\"))\n",
        "\n",
        "    with open(os.path.join(datafolder, \"data_High_noise\"), \"wb\") as f:\n",
        "        f.write(Noise_High_data.text.encode(\"utf-8\"))\n",
        "else:\n",
        "    print(\"Error in fetching data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sZCz-48ZBNw5"
      },
      "outputs": [],
      "source": [
        "Noise_0_dataframe = pd.read_csv(\"Data/Assignment1/data_0_noise\")\n",
        "Noise_Low_dataframe = pd.read_csv(\"Data/Assignment1/data_Low_noise\")\n",
        "Noise_High_dataframe = pd.read_csv(\"Data/Assignment1/data_High_noise\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKrqVPONBNw5",
        "outputId": "d0be1b06-6d08-4b0a-8610-33229693d6dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int64)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_index = list(Noise_0_dataframe[\"era\"].unique())\n",
        "class_index_noise = list(Noise_Low_dataframe[\"era\"].unique())\n",
        "def encode(value, class_index = class_index):\n",
        "    return class_index.index(value)\n",
        "\n",
        "def encode_noise(value, class_index = class_index_noise):\n",
        "    return class_index.index(value)\n",
        "\n",
        "Noise_0_dataframe[\"era\"] = Noise_0_dataframe[\"era\"].apply(encode)\n",
        "Noise_Low_dataframe[\"era\"] = Noise_Low_dataframe[\"era\"].apply(encode_noise)\n",
        "Noise_Low_dataframe[\"era\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_Jfvo6jBNw5"
      },
      "source": [
        "## Setting up Dataset & Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VYmSaMKKBNw6"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, noise, transform=None, target_transform=None,drop = None):\n",
        "        self.dataframe = dataframe\n",
        "        if drop != None:\n",
        "            self.X = dataframe.drop(drop, axis=1).values\n",
        "        else:\n",
        "            self.X = dataframe.values\n",
        "        self.y = dataframe[\"era\"].values\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.noise = noise\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item, label = self.X[idx], self.y[idx]\n",
        "        return item, label\n",
        "\n",
        "    def get_noise(self):\n",
        "        return self.noise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iUzwd5RYBNw6"
      },
      "outputs": [],
      "source": [
        "#Setting up datasets\n",
        "Noise_0_dataset = CustomDataset(Noise_0_dataframe, \"0\",drop = [\"row_num\",\"day\",\"era\",\"target_10_val\",\"target_5_val\"])\n",
        "Noise_Low_dataset = CustomDataset(Noise_Low_dataframe, \"Low\", drop = [\"row_num\",\"day\",\"era\",\"target_10_val\",\"target_5_val\",\"data_type\"])\n",
        "Noise_High_dataset = CustomDataset(Noise_High_dataframe, \"High\", drop = [\"row_num\",\"day\",\"era\",\"target_10_val\",\"target_5_val\",\"data_type\"])\n",
        "Noise_0_train, Noise_0_test = random_split(Noise_0_dataset, [int(0.8 * len(Noise_0_dataset)), len(Noise_0_dataset) - int(0.8 * len(Noise_0_dataset))])\n",
        "Noise_Low_train, Noise_Low_test = random_split(Noise_Low_dataset, [int(0.8 * len(Noise_Low_dataset)), len(Noise_Low_dataset) - int(0.8 * len(Noise_Low_dataset))])\n",
        "Noise_High_train, Noise_High_test = random_split(Noise_High_dataset, [int(0.8 * len(Noise_High_dataset)), len(Noise_High_dataset) - int(0.8 * len(Noise_High_dataset))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Q2QH7ZDlBNw6"
      },
      "outputs": [],
      "source": [
        "#Setting up dataloaders\n",
        "Noise_0_train_loader = DataLoader(Noise_0_train, batch_size=64, shuffle=True)\n",
        "Noise_0_test_loader = DataLoader(Noise_0_test, batch_size=64, shuffle=True)\n",
        "Noise_Low_train_loader = DataLoader(Noise_Low_train, batch_size=256, shuffle=True)\n",
        "Noise_Low_test_loader = DataLoader(Noise_Low_test, batch_size=256, shuffle=True)\n",
        "Noise_High_train_loader = DataLoader(Noise_High_train, batch_size=64, shuffle=True)\n",
        "Noise_High_test_loader = DataLoader(Noise_High_test, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWFHHoWmBNw7"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Zdu0tjhABNw7"
      },
      "outputs": [],
      "source": [
        "class MyMLP(torch.nn.Module):\n",
        "    def __init__ (self, modules):\n",
        "        super().__init__()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        MyModuleList = torch.nn.ModuleList([m for m in modules])\n",
        "        self.layers = torch.nn.Sequential(*MyModuleList)\n",
        "        self.softmax = torch.nn.Softmax(dim = 1)\n",
        "\n",
        "\n",
        "    def forward(self, X: torch.Tensor):\n",
        "        if (X.shape[1] != 24):\n",
        "            raise ValueError(\"Input shape must be (batch_size, 24)\")\n",
        "        X = X.to(device)\n",
        "        X = self.layers(X)\n",
        "        X = self.softmax(X)\n",
        "\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yVP0wCaX0p_0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Anaconda\\envs\\amlenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Import the libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchmetrics\n",
        "\n",
        "# Define the device to use\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the dataset class\n",
        "class Dataset(data.Dataset):\n",
        "  # Your code here\n",
        "  pass\n",
        "\n",
        "# Define the model class\n",
        "class Model(nn.Module):\n",
        "  # Your code here\n",
        "  pass\n",
        "\n",
        "# Define the ensemble classifier class\n",
        "class EnsembleClassifier():\n",
        "  def __init__(self, Dataset, num_classifiers, sample_percentage = 0.8):\n",
        "    # Initialize the ensemble\n",
        "    self.Dataset = Dataset\n",
        "    self.sample_percentage = sample_percentage\n",
        "    self.num_classifiers = num_classifiers\n",
        "    self.models = torch.nn.ModuleList()\n",
        "\n",
        "    # Create different models for each classifier\n",
        "    for clf in range(num_classifiers):\n",
        "      # You can use different architectures, hyperparameters, or dropout rates for each model\n",
        "      # Here I just use a simple linear model with a random number of features\n",
        "      num_features = torch.randint(10, 100, (1,)).item()\n",
        "      model = Model(num_features).to(device)\n",
        "      self.models.append(model)\n",
        "\n",
        "  def train(self, criterion, optimizer, batchsize, num_epochs):\n",
        "    # Get the number of samples in the dataset\n",
        "    num_samples = len(self.Dataset)\n",
        "    # Create a list of bootstrap dataloaders for each classifier\n",
        "    bootstrap_dataloaders = []\n",
        "    for c in range(self.num_classifiers):\n",
        "      # Create a weighted random sampler with replacement\n",
        "      weights = torch.ones(num_samples)\n",
        "      sampler = data.WeightedRandomSampler(weights, int(num_samples * self.sample_percentage), replacement=True)\n",
        "      # Create a dataloader with the sampler\n",
        "      sampled_dataloader = data.DataLoader(self.Dataset, batch_size = batchsize, sampler=sampler)\n",
        "      bootstrap_dataloaders.append(sampled_dataloader)\n",
        "\n",
        "    # Create a metric to compute the accuracy of each classifier and the ensemble\n",
        "    accuracy = torchmetrics.Accuracy().to(device)\n",
        "\n",
        "    # Train the ensemble\n",
        "    for epoch in range(num_epochs):\n",
        "      print(\"Starting Epoch-\", epoch)\n",
        "      # Initialize the epoch losses and accuracies\n",
        "      epoch_losses = torch.zeros(self.num_classifiers)\n",
        "      epoch_accuracies = torch.zeros(self.num_classifiers)\n",
        "      # Train each classifier\n",
        "      for model_num in range(len(self.models)):\n",
        "        # Set the model to train mode\n",
        "        self.models[model_num].train()\n",
        "        # Loop over the bootstrap dataloader\n",
        "        for inputs, labels in bootstrap_dataloaders[model_num]:\n",
        "          # Move the inputs and labels to the device\n",
        "          inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
        "          # Zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "          # Forward pass\n",
        "          outputs = self.modelsmodel_num\n",
        "          # Compute the loss\n",
        "          loss = criterion(outputs, labels)\n",
        "          # Backward pass and optimize\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          # Update the epoch loss\n",
        "          epoch_losses[model_num] += loss.item()\n",
        "          # Update the epoch accuracy\n",
        "          epoch_accuracies[model_num] += accuracy(outputs, labels)\n",
        "        # Compute the average epoch loss and accuracy\n",
        "        epoch_losses[model_num] /= len(bootstrap_dataloaders[model_num])\n",
        "        epoch_accuracies[model_num] /= len(bootstrap_dataloaders[model_num])\n",
        "        # Print the epoch loss and accuracy for each classifier\n",
        "        print(f\"Classifier {model_num}: Loss = {epoch_losses[model_num]:.4f}, Accuracy = {epoch_accuracies[model_num]:.4f}\")\n",
        "      # Compute the ensemble accuracy by averaging the predictions of each classifier\n",
        "      ensemble_accuracy = 0\n",
        "      # Loop over the original dataloader\n",
        "      for inputs, labels in data.DataLoader(self.Dataset, batch_size = batchsize):\n",
        "        # Move the inputs and labels to the device\n",
        "        inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
        "        # Initialize the ensemble predictions\n",
        "        ensemble_predictions = torch.zeros(inputs.size(0), device=device)\n",
        "        # Loop over each classifier\n",
        "        for model_num in range(len(self.models)):\n",
        "          # Set the model to eval mode\n",
        "          self.models[model_num].eval()\n",
        "          # Forward pass\n",
        "          outputs = self.modelsmodel_num\n",
        "          # Get the predictions\n",
        "          predictions = torch.argmax(outputs, dim=1)\n",
        "          # Add the predictions to the ensemble predictions\n",
        "          ensemble_predictions += predictions\n",
        "        # Get the majority vote of the ensemble predictions\n",
        "        ensemble_predictions = torch.round(ensemble_predictions / self.num_classifiers)\n",
        "        # Update the ensemble accuracy\n",
        "        ensemble_accuracy += accuracy(ensemble_predictions, labels)\n",
        "      # Compute the average ensemble accuracy\n",
        "      ensemble_accuracy /= len(data.DataLoader(self.Dataset, batch_size = batchsize))\n",
        "      # Print the ensemble accuracy\n",
        "      print(f\"Ensemble: Accuracy = {ensemble_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wWEVAs-7lFyR"
      },
      "outputs": [],
      "source": [
        "class EnsembleClassifier():\n",
        "  def __init__(self, Dataset, num_classifiers,sample_percentage = 0.8):\n",
        "    self.Dataset = Dataset\n",
        "    self.sample_percentage = sample_percentage\n",
        "    self.num_classifiers = num_classifiers\n",
        "    self.models = torch.nn.ModuleList()\n",
        "\n",
        "    #Currently hard coded the model, change later\n",
        "    for clf in range(num_classifiers):\n",
        "      self.models.append(MyMLP([torch.nn.Linear(24,64),torch.nn.ReLU(),torch.nn.Linear(64,128),torch.nn.Dropout(p = 0.2),torch.nn.ReLU(),torch.nn.Linear(128,64),torch.nn.Dropout(p = 0.2),torch.nn.ReLU(),torch.nn.Linear(64,12)]).to(device))\n",
        "\n",
        "  def train(self,criterion,batchsize,num_epochs):\n",
        "      num_samples = int(0.8 * len(self.Dataset))\n",
        "      indices = list(range(num_samples))\n",
        "      bootstrap_dataloaders = []\n",
        "      accuracy = torchmetrics.Accuracy(task = \"multiclass\",num_classes = 12).to(device)\n",
        "\n",
        "      for c in range(self.num_classifiers):\n",
        "          sampled_indices = torch.randperm(num_samples)[:int(num_samples * self.sample_percentage)]\n",
        "          sampler = SubsetRandomSampler(sampled_indices)\n",
        "          sampled_dataloader = DataLoader(self.Dataset, batch_size = batchsize, sampler=sampler)\n",
        "          bootstrap_dataloaders.append(sampled_dataloader)\n",
        "\n",
        "      for epoch in range(num_epochs):\n",
        "        print(\"Starting Epoch-\",epoch)\n",
        "        epoch_losses = torch.zeros(self.num_classifiers).to(device)\n",
        "        epoch_accuracies = torch.zeros(self.num_classifiers).to(device)\n",
        "        for model_num in range(len(self.models)):\n",
        "          optimizer = optim.Adam(self.models[model_num].parameters(), lr=0.0001, weight_decay=0.001)\n",
        "          self.models[model_num].train()\n",
        "          for inputs, labels in bootstrap_dataloaders[model_num]:\n",
        "            inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = self.models[model_num](inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_losses[model_num] += loss.item()\n",
        "            epoch_accuracies[model_num] += accuracy(outputs, labels)\n",
        "\n",
        "          epoch_losses[model_num] /= len(bootstrap_dataloaders[model_num])\n",
        "          epoch_accuracies[model_num] /= len(bootstrap_dataloaders[model_num])\n",
        "          print(f\"Classifier {model_num}: Loss = {epoch_losses[model_num]:.4f}, Accuracy = {epoch_accuracies[model_num]:.4f}\")\n",
        "\n",
        "  def forward(self, x):\n",
        "    ensemble_predictions = torch.zeros(x.size(0), 12, device=device)\n",
        "    for model_num in range(len(self.models)):\n",
        "      self.models[model_num].eval()\n",
        "      outputs = self.models[model_num](x)\n",
        "      ensemble_predictions += outputs\n",
        "    ensemble_predictions /= self.num_classifiers\n",
        "    return ensemble_predictions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFmCKdxHBNw7"
      },
      "outputs": [],
      "source": [
        "Model = MyMLP([torch.nn.Linear(24,64),torch.nn.ReLU(),torch.nn.Linear(64,128),torch.nn.Dropout(p = 0.2),torch.nn.ReLU(),torch.nn.Linear(128,64),torch.nn.Dropout(p = 0.2),torch.nn.ReLU(),torch.nn.Linear(64,12)])\n",
        "Model = Model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KOB_XCYweg7",
        "outputId": "ecba5d07-6610-4f93-b91d-431a8a8a7446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Epoch- 0\n",
            "Classifier 0: Loss = 2.4328, Accuracy = 0.1635\n",
            "Classifier 1: Loss = 2.4332, Accuracy = 0.1657\n",
            "Classifier 2: Loss = 2.4344, Accuracy = 0.1598\n",
            "Classifier 3: Loss = 2.4284, Accuracy = 0.1853\n",
            "Classifier 4: Loss = 2.4329, Accuracy = 0.1761\n",
            "Starting Epoch- 1\n",
            "Classifier 0: Loss = 2.3595, Accuracy = 0.2601\n",
            "Classifier 1: Loss = 2.3575, Accuracy = 0.2638\n",
            "Classifier 2: Loss = 2.3604, Accuracy = 0.2602\n",
            "Classifier 3: Loss = 2.3584, Accuracy = 0.2605\n",
            "Classifier 4: Loss = 2.3619, Accuracy = 0.2573\n",
            "Starting Epoch- 2\n",
            "Classifier 0: Loss = 2.3447, Accuracy = 0.2734\n",
            "Classifier 1: Loss = 2.3383, Accuracy = 0.2797\n",
            "Classifier 2: Loss = 2.3434, Accuracy = 0.2744\n",
            "Classifier 3: Loss = 2.3416, Accuracy = 0.2748\n",
            "Classifier 4: Loss = 2.3468, Accuracy = 0.2709\n",
            "Starting Epoch- 3\n",
            "Classifier 0: Loss = 2.3354, Accuracy = 0.2789\n",
            "Classifier 1: Loss = 2.3001, Accuracy = 0.3216\n",
            "Classifier 2: Loss = 2.3282, Accuracy = 0.2871\n",
            "Classifier 3: Loss = 2.3185, Accuracy = 0.2996\n",
            "Classifier 4: Loss = 2.3390, Accuracy = 0.2763\n",
            "Starting Epoch- 4\n",
            "Classifier 0: Loss = 2.3239, Accuracy = 0.2876\n",
            "Classifier 1: Loss = 2.2643, Accuracy = 0.3615\n",
            "Classifier 2: Loss = 2.2947, Accuracy = 0.3258\n",
            "Classifier 3: Loss = 2.2848, Accuracy = 0.3384\n",
            "Classifier 4: Loss = 2.3320, Accuracy = 0.2803\n",
            "Starting Epoch- 5\n",
            "Classifier 0: Loss = 2.2926, Accuracy = 0.3278\n",
            "Classifier 1: Loss = 2.2385, Accuracy = 0.3883\n",
            "Classifier 2: Loss = 2.2665, Accuracy = 0.3599\n",
            "Classifier 3: Loss = 2.2634, Accuracy = 0.3625\n",
            "Classifier 4: Loss = 2.3232, Accuracy = 0.2863\n",
            "Starting Epoch- 6\n",
            "Classifier 0: Loss = 2.2616, Accuracy = 0.3620\n",
            "Classifier 1: Loss = 2.2207, Accuracy = 0.4061\n",
            "Classifier 2: Loss = 2.2422, Accuracy = 0.3843\n",
            "Classifier 3: Loss = 2.2417, Accuracy = 0.3844\n",
            "Classifier 4: Loss = 2.2996, Accuracy = 0.3194\n",
            "Starting Epoch- 7\n",
            "Classifier 0: Loss = 2.2369, Accuracy = 0.3895\n",
            "Classifier 1: Loss = 2.2102, Accuracy = 0.4180\n",
            "Classifier 2: Loss = 2.2266, Accuracy = 0.4012\n",
            "Classifier 3: Loss = 2.2264, Accuracy = 0.4003\n",
            "Classifier 4: Loss = 2.2694, Accuracy = 0.3547\n",
            "Starting Epoch- 8\n",
            "Classifier 0: Loss = 2.2213, Accuracy = 0.4052\n",
            "Classifier 1: Loss = 2.2015, Accuracy = 0.4278\n",
            "Classifier 2: Loss = 2.2159, Accuracy = 0.4132\n",
            "Classifier 3: Loss = 2.2157, Accuracy = 0.4126\n",
            "Classifier 4: Loss = 2.2451, Accuracy = 0.3798\n",
            "Starting Epoch- 9\n",
            "Classifier 0: Loss = 2.2117, Accuracy = 0.4158\n",
            "Classifier 1: Loss = 2.1950, Accuracy = 0.4354\n",
            "Classifier 2: Loss = 2.2078, Accuracy = 0.4213\n",
            "Classifier 3: Loss = 2.2076, Accuracy = 0.4215\n",
            "Classifier 4: Loss = 2.2293, Accuracy = 0.3955\n"
          ]
        }
      ],
      "source": [
        "Ensemble = EnsembleClassifier(Noise_Low_dataset,5,0.7)\n",
        "Ensemble.train(torch.nn.CrossEntropyLoss(),128,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "hFlXfShY7Bee",
        "outputId": "fa58e9f2-0840-4635-9970-486e08ec30b4"
      },
      "outputs": [],
      "source": [
        "for input,label in Noise_Low_test_loader:\n",
        "  input, label = input.to(device).to(torch.float32), label.to(device).to(torch.long)\n",
        "  outputs = Ensemble.forward(input)\n",
        "  predicted_labels = torch.argmax(outputs, dim=1)\n",
        "  print((predicted_labels == label).sum()/256)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PgsVEXEjT7ub"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10,verbose=True):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_train_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_train_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_train_loss / len(train_loader)\n",
        "        train_accuracy = correct_train / total_train\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                running_val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total_val += labels.size(0)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = running_val_loss / len(val_loader)\n",
        "        val_accuracy = correct_val / total_val\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
        "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(1, num_epochs + 1), train_losses, label='Train')\n",
        "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train')\n",
        "    plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RSMHnpcvT7uc",
        "outputId": "c4e8a53f-fc01-4581-8888-5bf5de246367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Train Loss: 2.1665, Train Acc: 0.4598, Val Loss: 2.0659, Val Acc: 0.5568\n",
            "Epoch [2/100], Train Loss: 2.0517, Train Acc: 0.5720, Val Loss: 2.0280, Val Acc: 0.5948\n",
            "Epoch [3/100], Train Loss: 2.0327, Train Acc: 0.5901, Val Loss: 2.0134, Val Acc: 0.6078\n",
            "Epoch [4/100], Train Loss: 2.0155, Train Acc: 0.6080, Val Loss: 1.9584, Val Acc: 0.6662\n",
            "Epoch [5/100], Train Loss: 1.9600, Train Acc: 0.6642, Val Loss: 1.9402, Val Acc: 0.6810\n",
            "Epoch [6/100], Train Loss: 1.9300, Train Acc: 0.6951, Val Loss: 1.9033, Val Acc: 0.7201\n",
            "Epoch [7/100], Train Loss: 1.9160, Train Acc: 0.7083, Val Loss: 1.8943, Val Acc: 0.7278\n",
            "Epoch [8/100], Train Loss: 1.9067, Train Acc: 0.7174, Val Loss: 1.8927, Val Acc: 0.7304\n",
            "Epoch [9/100], Train Loss: 1.9004, Train Acc: 0.7240, Val Loss: 1.8859, Val Acc: 0.7350\n",
            "Epoch [10/100], Train Loss: 1.8969, Train Acc: 0.7269, Val Loss: 1.8754, Val Acc: 0.7474\n",
            "Epoch [11/100], Train Loss: 1.8916, Train Acc: 0.7325, Val Loss: 1.8774, Val Acc: 0.7442\n",
            "Epoch [12/100], Train Loss: 1.8892, Train Acc: 0.7349, Val Loss: 1.8747, Val Acc: 0.7457\n",
            "Epoch [13/100], Train Loss: 1.8864, Train Acc: 0.7372, Val Loss: 1.8677, Val Acc: 0.7551\n",
            "Epoch [14/100], Train Loss: 1.8829, Train Acc: 0.7407, Val Loss: 1.8659, Val Acc: 0.7563\n",
            "Epoch [15/100], Train Loss: 1.8810, Train Acc: 0.7427, Val Loss: 1.8651, Val Acc: 0.7558\n",
            "Epoch [16/100], Train Loss: 1.8790, Train Acc: 0.7451, Val Loss: 1.8612, Val Acc: 0.7601\n",
            "Epoch [17/100], Train Loss: 1.8771, Train Acc: 0.7470, Val Loss: 1.8681, Val Acc: 0.7534\n",
            "Epoch [18/100], Train Loss: 1.8752, Train Acc: 0.7483, Val Loss: 1.8799, Val Acc: 0.7429\n",
            "Epoch [19/100], Train Loss: 1.8738, Train Acc: 0.7497, Val Loss: 1.8614, Val Acc: 0.7609\n",
            "Epoch [20/100], Train Loss: 1.8728, Train Acc: 0.7509, Val Loss: 1.8547, Val Acc: 0.7666\n",
            "Epoch [21/100], Train Loss: 1.8703, Train Acc: 0.7532, Val Loss: 1.8550, Val Acc: 0.7668\n",
            "Epoch [22/100], Train Loss: 1.8701, Train Acc: 0.7533, Val Loss: 1.8579, Val Acc: 0.7633\n",
            "Epoch [23/100], Train Loss: 1.8695, Train Acc: 0.7539, Val Loss: 1.8558, Val Acc: 0.7669\n",
            "Epoch [24/100], Train Loss: 1.8671, Train Acc: 0.7565, Val Loss: 1.8549, Val Acc: 0.7673\n",
            "Epoch [25/100], Train Loss: 1.8667, Train Acc: 0.7570, Val Loss: 1.8673, Val Acc: 0.7521\n",
            "Epoch [26/100], Train Loss: 1.8660, Train Acc: 0.7578, Val Loss: 1.8507, Val Acc: 0.7712\n",
            "Epoch [27/100], Train Loss: 1.8642, Train Acc: 0.7594, Val Loss: 1.8533, Val Acc: 0.7677\n",
            "Epoch [28/100], Train Loss: 1.8643, Train Acc: 0.7594, Val Loss: 1.8516, Val Acc: 0.7708\n",
            "Epoch [29/100], Train Loss: 1.8642, Train Acc: 0.7591, Val Loss: 1.8472, Val Acc: 0.7750\n",
            "Epoch [30/100], Train Loss: 1.8624, Train Acc: 0.7613, Val Loss: 1.8484, Val Acc: 0.7733\n",
            "Epoch [31/100], Train Loss: 1.8621, Train Acc: 0.7615, Val Loss: 1.8560, Val Acc: 0.7638\n",
            "Epoch [32/100], Train Loss: 1.8603, Train Acc: 0.7634, Val Loss: 1.8457, Val Acc: 0.7762\n",
            "Epoch [33/100], Train Loss: 1.8597, Train Acc: 0.7642, Val Loss: 1.8492, Val Acc: 0.7733\n",
            "Epoch [34/100], Train Loss: 1.8583, Train Acc: 0.7655, Val Loss: 1.8460, Val Acc: 0.7752\n",
            "Epoch [35/100], Train Loss: 1.8582, Train Acc: 0.7655, Val Loss: 1.8459, Val Acc: 0.7755\n",
            "Epoch [36/100], Train Loss: 1.8578, Train Acc: 0.7658, Val Loss: 1.8421, Val Acc: 0.7782\n",
            "Epoch [37/100], Train Loss: 1.8571, Train Acc: 0.7665, Val Loss: 1.8415, Val Acc: 0.7803\n",
            "Epoch [38/100], Train Loss: 1.8563, Train Acc: 0.7673, Val Loss: 1.8411, Val Acc: 0.7799\n",
            "Epoch [39/100], Train Loss: 1.8553, Train Acc: 0.7681, Val Loss: 1.8388, Val Acc: 0.7833\n",
            "Epoch [40/100], Train Loss: 1.8549, Train Acc: 0.7691, Val Loss: 1.8381, Val Acc: 0.7844\n",
            "Epoch [41/100], Train Loss: 1.8541, Train Acc: 0.7697, Val Loss: 1.8513, Val Acc: 0.7706\n",
            "Epoch [42/100], Train Loss: 1.8537, Train Acc: 0.7704, Val Loss: 1.8412, Val Acc: 0.7798\n",
            "Epoch [43/100], Train Loss: 1.8530, Train Acc: 0.7704, Val Loss: 1.8429, Val Acc: 0.7783\n",
            "Epoch [44/100], Train Loss: 1.8524, Train Acc: 0.7718, Val Loss: 1.8373, Val Acc: 0.7844\n",
            "Epoch [45/100], Train Loss: 1.8523, Train Acc: 0.7714, Val Loss: 1.8423, Val Acc: 0.7788\n",
            "Epoch [46/100], Train Loss: 1.8523, Train Acc: 0.7717, Val Loss: 1.8438, Val Acc: 0.7780\n",
            "Epoch [47/100], Train Loss: 1.8518, Train Acc: 0.7722, Val Loss: 1.8418, Val Acc: 0.7803\n",
            "Epoch [48/100], Train Loss: 1.8519, Train Acc: 0.7714, Val Loss: 1.8358, Val Acc: 0.7853\n",
            "Epoch [49/100], Train Loss: 1.8513, Train Acc: 0.7723, Val Loss: 1.8387, Val Acc: 0.7831\n",
            "Epoch [50/100], Train Loss: 1.8498, Train Acc: 0.7739, Val Loss: 1.8382, Val Acc: 0.7824\n",
            "Epoch [51/100], Train Loss: 1.8493, Train Acc: 0.7741, Val Loss: 1.8359, Val Acc: 0.7862\n",
            "Epoch [52/100], Train Loss: 1.8494, Train Acc: 0.7743, Val Loss: 1.8439, Val Acc: 0.7779\n",
            "Epoch [53/100], Train Loss: 1.8486, Train Acc: 0.7752, Val Loss: 1.8412, Val Acc: 0.7796\n",
            "Epoch [54/100], Train Loss: 1.8478, Train Acc: 0.7760, Val Loss: 1.8346, Val Acc: 0.7869\n",
            "Epoch [55/100], Train Loss: 1.8481, Train Acc: 0.7755, Val Loss: 1.8337, Val Acc: 0.7875\n",
            "Epoch [56/100], Train Loss: 1.8477, Train Acc: 0.7764, Val Loss: 1.8349, Val Acc: 0.7871\n",
            "Epoch [57/100], Train Loss: 1.8468, Train Acc: 0.7773, Val Loss: 1.8461, Val Acc: 0.7761\n",
            "Epoch [58/100], Train Loss: 1.8467, Train Acc: 0.7773, Val Loss: 1.8329, Val Acc: 0.7878\n",
            "Epoch [59/100], Train Loss: 1.8464, Train Acc: 0.7773, Val Loss: 1.8360, Val Acc: 0.7856\n",
            "Epoch [60/100], Train Loss: 1.8461, Train Acc: 0.7776, Val Loss: 1.8338, Val Acc: 0.7881\n",
            "Epoch [61/100], Train Loss: 1.8459, Train Acc: 0.7782, Val Loss: 1.8341, Val Acc: 0.7882\n",
            "Epoch [62/100], Train Loss: 1.8448, Train Acc: 0.7789, Val Loss: 1.8334, Val Acc: 0.7875\n",
            "Epoch [63/100], Train Loss: 1.8441, Train Acc: 0.7795, Val Loss: 1.8403, Val Acc: 0.7804\n",
            "Epoch [64/100], Train Loss: 1.8448, Train Acc: 0.7788, Val Loss: 1.8361, Val Acc: 0.7860\n",
            "Epoch [65/100], Train Loss: 1.8437, Train Acc: 0.7802, Val Loss: 1.8294, Val Acc: 0.7924\n",
            "Epoch [66/100], Train Loss: 1.8436, Train Acc: 0.7806, Val Loss: 1.8306, Val Acc: 0.7911\n",
            "Epoch [67/100], Train Loss: 1.8431, Train Acc: 0.7810, Val Loss: 1.8346, Val Acc: 0.7860\n",
            "Epoch [68/100], Train Loss: 1.8430, Train Acc: 0.7809, Val Loss: 1.8329, Val Acc: 0.7881\n",
            "Epoch [69/100], Train Loss: 1.8435, Train Acc: 0.7807, Val Loss: 1.8305, Val Acc: 0.7909\n",
            "Epoch [70/100], Train Loss: 1.8425, Train Acc: 0.7814, Val Loss: 1.8304, Val Acc: 0.7908\n",
            "Epoch [71/100], Train Loss: 1.8431, Train Acc: 0.7803, Val Loss: 1.8291, Val Acc: 0.7931\n",
            "Epoch [72/100], Train Loss: 1.8422, Train Acc: 0.7817, Val Loss: 1.8343, Val Acc: 0.7864\n",
            "Epoch [73/100], Train Loss: 1.8420, Train Acc: 0.7818, Val Loss: 1.8305, Val Acc: 0.7906\n",
            "Epoch [74/100], Train Loss: 1.8421, Train Acc: 0.7817, Val Loss: 1.8347, Val Acc: 0.7872\n",
            "Epoch [75/100], Train Loss: 1.8414, Train Acc: 0.7825, Val Loss: 1.8328, Val Acc: 0.7901\n",
            "Epoch [76/100], Train Loss: 1.8420, Train Acc: 0.7819, Val Loss: 1.8279, Val Acc: 0.7942\n",
            "Epoch [77/100], Train Loss: 1.8417, Train Acc: 0.7815, Val Loss: 1.8325, Val Acc: 0.7899\n",
            "Epoch [78/100], Train Loss: 1.8419, Train Acc: 0.7819, Val Loss: 1.8336, Val Acc: 0.7875\n",
            "Epoch [79/100], Train Loss: 1.8412, Train Acc: 0.7825, Val Loss: 1.8270, Val Acc: 0.7954\n",
            "Epoch [80/100], Train Loss: 1.8408, Train Acc: 0.7831, Val Loss: 1.8362, Val Acc: 0.7848\n",
            "Epoch [81/100], Train Loss: 1.8411, Train Acc: 0.7826, Val Loss: 1.8333, Val Acc: 0.7878\n",
            "Epoch [82/100], Train Loss: 1.8413, Train Acc: 0.7825, Val Loss: 1.8362, Val Acc: 0.7858\n",
            "Epoch [83/100], Train Loss: 1.8412, Train Acc: 0.7827, Val Loss: 1.8363, Val Acc: 0.7862\n",
            "Epoch [84/100], Train Loss: 1.8408, Train Acc: 0.7829, Val Loss: 1.8283, Val Acc: 0.7932\n",
            "Epoch [85/100], Train Loss: 1.8402, Train Acc: 0.7833, Val Loss: 1.8272, Val Acc: 0.7952\n",
            "Epoch [86/100], Train Loss: 1.8403, Train Acc: 0.7835, Val Loss: 1.8306, Val Acc: 0.7908\n",
            "Epoch [87/100], Train Loss: 1.8406, Train Acc: 0.7829, Val Loss: 1.8430, Val Acc: 0.7788\n",
            "Epoch [88/100], Train Loss: 1.8401, Train Acc: 0.7837, Val Loss: 1.8336, Val Acc: 0.7879\n",
            "Epoch [89/100], Train Loss: 1.8391, Train Acc: 0.7848, Val Loss: 1.8335, Val Acc: 0.7889\n",
            "Epoch [90/100], Train Loss: 1.8393, Train Acc: 0.7847, Val Loss: 1.8294, Val Acc: 0.7929\n",
            "Epoch [91/100], Train Loss: 1.8392, Train Acc: 0.7844, Val Loss: 1.8286, Val Acc: 0.7935\n",
            "Epoch [92/100], Train Loss: 1.8394, Train Acc: 0.7844, Val Loss: 1.8499, Val Acc: 0.7705\n",
            "Epoch [93/100], Train Loss: 1.8393, Train Acc: 0.7844, Val Loss: 1.8345, Val Acc: 0.7873\n",
            "Epoch [94/100], Train Loss: 1.8394, Train Acc: 0.7842, Val Loss: 1.8312, Val Acc: 0.7892\n",
            "Epoch [95/100], Train Loss: 1.8392, Train Acc: 0.7846, Val Loss: 1.8291, Val Acc: 0.7924\n",
            "Epoch [96/100], Train Loss: 1.8389, Train Acc: 0.7846, Val Loss: 1.8324, Val Acc: 0.7888\n",
            "Epoch [97/100], Train Loss: 1.8385, Train Acc: 0.7852, Val Loss: 1.8292, Val Acc: 0.7921\n",
            "Epoch [98/100], Train Loss: 1.8381, Train Acc: 0.7858, Val Loss: 1.8269, Val Acc: 0.7949\n",
            "Epoch [99/100], Train Loss: 1.8384, Train Acc: 0.7852, Val Loss: 1.8292, Val Acc: 0.7922\n",
            "Epoch [100/100], Train Loss: 1.8383, Train Acc: 0.7854, Val Loss: 1.8281, Val Acc: 0.7929\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Model = MyMLP([torch.nn.Linear(24,64),torch.nn.ReLU(),torch.nn.Linear(64,256),torch.nn.Dropout(p = 0.2),torch.nn.ReLU(),torch.nn.Linear(256,64),torch.nn.Dropout(p = 0.2),torch.nn.ReLU(),torch.nn.Linear(64,12)]).to(device)\n",
        "optimizer = optim.Adam(Model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "train_model(Model,torch.nn.CrossEntropyLoss(), optimizer,Noise_Low_train_loader, Noise_Low_test_loader,num_epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EiFVifQGT7uc"
      },
      "outputs": [],
      "source": [
        "PATH = \"model.pt\"\n",
        "\n",
        "# Save the model\n",
        "torch.save(Model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "38o5IWpRT7uc",
        "outputId": "721d6010-3b0b-4d06-9570-0e22d7b11463"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "PATH = \"model.pt\"\n",
        "\n",
        "# Load the model\n",
        "Model.load_state_dict(torch.load(PATH))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b32HVbvcPSjV"
      },
      "source": [
        "## Lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKRoQ3NnBNw8"
      },
      "outputs": [],
      "source": [
        "from lightning.pytorch.utilities.types import OptimizerLRScheduler\n",
        "\n",
        "\n",
        "class LightningMLP(L.LightningModule):\n",
        "    def __init__(self, model, loss, optimizer):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.loss = loss\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        inputs, targets = batch\n",
        "        inputs, targets = torch.tensor(inputs).to(torch.float32),torch.tensor(targets).to(torch.long)\n",
        "        inputs, targets = inputs.to(device),targets.to(device)\n",
        "        output = self.model(inputs)\n",
        "        loss = self.loss(output, targets)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self,batch,batch_idx):\n",
        "        inputs, targets = batch\n",
        "        inputs, targets = torch.tensor(inputs).to(torch.float32),torch.tensor(targets).to(torch.long)\n",
        "        inputs, targets = inputs.to(device),targets.to(device)\n",
        "        output = self.model(inputs)\n",
        "        loss = self.loss(output, targets)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return self.optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659,
          "referenced_widgets": [
            "0c0de4b95e4545c0bbe9eafea153125b",
            "bd0232e4017240debb92efe3100b71a3",
            "32fad7dacf594cb488bf6a261f933f8b",
            "613424989e984c8888528d3a4d61a318",
            "1ab03e476b624c699cc85fb8d9ec71a1",
            "95bf24f9ca0b4baab139e7716dffb754",
            "3e901c104db34d8a88a632d8d897022b",
            "a2d642748e7c4d81a2ab1ec8d9720926",
            "5217d52572ba41ceba0130b5ac47af5b",
            "2a39fbb734d74e8b9b9f44a0627b35a2",
            "abbe93dc21094598aa884f59e3b4aaab",
            "8dcf7890b2984588abf21669aafd8363"
          ]
        },
        "id": "jvabAADABNw8",
        "outputId": "54d61c56-84f6-4338-9e38-1cedc2838bff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Deeptanshu Barman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:72: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type  | Params\n",
            "--------------------------------\n",
            "0 | model | MyMLP | 6.5 K \n",
            "--------------------------------\n",
            "6.5 K     Trainable params\n",
            "0         Non-trainable params\n",
            "6.5 K     Total params\n",
            "0.026     Total estimated model params size (MB)\n",
            "C:\\Users\\Deeptanshu Barman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dcf7890b2984588abf21669aafd8363",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\temp\\ipykernel_16032\\3998816417.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  inputs, targets = torch.tensor(inputs).to(torch.float32),torch.tensor(targets).to(torch.long)\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Boolean value of Tensor with more than one value is ambiguous",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[40], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m mymodel \u001b[38;5;241m=\u001b[39m LightningMLP(Model, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss, torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(Model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m))\n\u001b[0;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer(max_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmymodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNoise_0_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNoise_0_test_loader\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    576\u001b[0m     ckpt_path,\n\u001b[0;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    579\u001b[0m )\n\u001b[1;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:989\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 989\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    994\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1035\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1033\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[0;32m   1034\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1035\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:202\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:359\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:136\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:240\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:187\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[1;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m         closure()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:265\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[1;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\trainer\\call.py:157\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 157\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    160\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\core\\module.py:1291\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1254\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1257\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1258\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;124;03m    the optimizer.\u001b[39;00m\n\u001b[0;32m   1261\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1289\u001b[0m \n\u001b[0;32m   1290\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1291\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\core\\optimizer.py:151\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy\u001b[38;5;241m.\u001b[39moptimizer_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer, closure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:230\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[1;32m--> 230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39moptimizer_step(optimizer, model\u001b[38;5;241m=\u001b[39mmodel, closure\u001b[38;5;241m=\u001b[39mclosure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision.py:117\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[1;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimizer\u001b[38;5;241m.\u001b[39mstep(closure\u001b[38;5;241m=\u001b[39mclosure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\adam.py:183\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 183\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[0;32m    186\u001b[0m     params_with_grad \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision.py:104\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[1;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     93\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     94\u001b[0m     optimizer: Optimizer,\n\u001b[0;32m     95\u001b[0m     closure: Callable[[], Any],\n\u001b[0;32m     96\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    hook is called.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:140\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosure(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:126\u001b[0m, in \u001b[0;36mClosure.closure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[1;32m--> 126\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:315\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m    314\u001b[0m \u001b[38;5;66;03m# manually capture logged metrics\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_result_cls\u001b[38;5;241m.\u001b[39mfrom_training_step_output(training_step_output, trainer\u001b[38;5;241m.\u001b[39maccumulate_grad_batches)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\trainer\\call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:382\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mtraining_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "Cell \u001b[1;32mIn[20], line 16\u001b[0m, in \u001b[0;36mLightningMLP.training_step\u001b[1;34m(self, batch, batch_idx)\u001b[0m\n\u001b[0;32m     14\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device),targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(inputs)\n\u001b[1;32m---> 16\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\loss.py:1169\u001b[0m, in \u001b[0;36mCrossEntropyLoss.__init__\u001b[1;34m(self, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, size_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_index: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m   1168\u001b[0m              reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, label_smoothing: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1169\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index \u001b[38;5;241m=\u001b[39m ignore_index\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing \u001b[38;5;241m=\u001b[39m label_smoothing\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\loss.py:30\u001b[0m, in \u001b[0;36m_WeightedLoss.__init__\u001b[1;34m(self, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, weight: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, size_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, reduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_WeightedLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m, weight)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight: Optional[Tensor]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\loss.py:23\u001b[0m, in \u001b[0;36m_Loss.__init__\u001b[1;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28msuper\u001b[39m(_Loss, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegacy_get_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction \u001b[38;5;241m=\u001b[39m reduction\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\_reduction.py:35\u001b[0m, in \u001b[0;36mlegacy_get_string\u001b[1;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     reduce \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mand\u001b[39;00m reduce:\n\u001b[0;32m     36\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m reduce:\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
          ]
        }
      ],
      "source": [
        "mymodel = LightningMLP(Model, torch.nn.CrossEntropyLoss, torch.optim.Adam(Model.parameters(), lr=0.001))\n",
        "trainer = L.Trainer(max_epochs = 10)\n",
        "trainer.fit(mymodel, Noise_0_train_loader, Noise_0_test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c0de4b95e4545c0bbe9eafea153125b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd0232e4017240debb92efe3100b71a3",
              "IPY_MODEL_32fad7dacf594cb488bf6a261f933f8b",
              "IPY_MODEL_613424989e984c8888528d3a4d61a318"
            ],
            "layout": "IPY_MODEL_1ab03e476b624c699cc85fb8d9ec71a1"
          }
        },
        "1ab03e476b624c699cc85fb8d9ec71a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "2a39fbb734d74e8b9b9f44a0627b35a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32fad7dacf594cb488bf6a261f933f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2d642748e7c4d81a2ab1ec8d9720926",
            "max": 98,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5217d52572ba41ceba0130b5ac47af5b",
            "value": 98
          }
        },
        "3e901c104db34d8a88a632d8d897022b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5217d52572ba41ceba0130b5ac47af5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "613424989e984c8888528d3a4d61a318": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a39fbb734d74e8b9b9f44a0627b35a2",
            "placeholder": "​",
            "style": "IPY_MODEL_abbe93dc21094598aa884f59e3b4aaab",
            "value": " 98/98 [00:00&lt;00:00, 280.28it/s, v_num=3]"
          }
        },
        "95bf24f9ca0b4baab139e7716dffb754": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d642748e7c4d81a2ab1ec8d9720926": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abbe93dc21094598aa884f59e3b4aaab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd0232e4017240debb92efe3100b71a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95bf24f9ca0b4baab139e7716dffb754",
            "placeholder": "​",
            "style": "IPY_MODEL_3e901c104db34d8a88a632d8d897022b",
            "value": "Epoch 9: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
