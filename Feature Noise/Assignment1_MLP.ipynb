{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVH3nOPYBNw0"
      },
      "source": [
        "# Assignment-1\n",
        "## Team: Aditya Ahuja (2020275), Deeptanshu Barman Chowdhuri (2020293)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro-XJmUCBNw3"
      },
      "source": [
        "##  Imports & Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NmATk9NBNw3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import requests\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "import lightning as L\n",
        "import torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spHzIt_dFTM6"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "# device = \"cpu\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXoJtlecBNw4"
      },
      "outputs": [],
      "source": [
        "Noise_0_data = requests.get(\n",
        "    \"http://AdityaAhuja01.pythonanywhere.com/data/df_syn_train_0_0_.csv\"\n",
        ")\n",
        "Noise_Low_data = requests.get(\n",
        "    \"http://AdityaAhuja01.pythonanywhere.com/data/df_synA_train_shuffled.csv\"\n",
        ")\n",
        "Noise_High_data = requests.get(\n",
        "    \"http://AdityaAhuja01.pythonanywhere.com/data/df_synA_test_hard_shuffled_sample.csv\"\n",
        ")\n",
        "\n",
        "if Noise_0_data.status_code == 200 and Noise_Low_data.status_code == 200 and Noise_High_data.status_code == 200:\n",
        "    datafolder = \"Data/Assignment1\"\n",
        "\n",
        "    if not os.path.exists(datafolder):\n",
        "        os.makedirs(datafolder)\n",
        "\n",
        "    with open(os.path.join(datafolder, \"data_0_noise\"), \"wb\") as f:\n",
        "        f.write(Noise_0_data.text.encode(\"utf-8\"))\n",
        "\n",
        "    with open(os.path.join(datafolder, \"data_Low_noise\"), \"wb\") as f:\n",
        "        f.write(Noise_Low_data.text.encode(\"utf-8\"))\n",
        "\n",
        "    with open(os.path.join(datafolder, \"data_High_noise\"), \"wb\") as f:\n",
        "        f.write(Noise_High_data.text.encode(\"utf-8\"))\n",
        "else:\n",
        "    print(\"Error in fetching data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZCz-48ZBNw5"
      },
      "outputs": [],
      "source": [
        "Noise_0_dataframe = pd.read_csv(\"Data/Assignment1/data_0_noise\")\n",
        "Noise_Low_dataframe = pd.read_csv(\"Data/Assignment1/data_Low_noise\")\n",
        "Noise_High_dataframe = pd.read_csv(\"Data/Assignment1/data_High_noise\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKrqVPONBNw5",
        "outputId": "d0be1b06-6d08-4b0a-8610-33229693d6dd"
      },
      "outputs": [],
      "source": [
        "class_index = list(Noise_0_dataframe[\"era\"].unique())\n",
        "class_index_noise = list(Noise_Low_dataframe[\"era\"].unique())\n",
        "class_index_target = list(Noise_High_dataframe[\"target_10_val\"].unique())\n",
        "def encode(value, class_index = class_index):\n",
        "    return class_index.index(value)\n",
        "\n",
        "def encode_noise(value, class_index = class_index_noise):\n",
        "    return class_index.index(value)\n",
        "\n",
        "def encode_target(value, class_index = class_index_target):\n",
        "    return class_index.index(value)\n",
        "\n",
        "# Noise_0_dataframe[\"era\"] = Noise_0_dataframe[\"era\"].apply(encode)\n",
        "# Noise_Low_dataframe[\"era\"] = Noise_Low_dataframe[\"era\"].apply(encode_noise)\n",
        "Noise_High_dataframe[\"target_10_val\"] = Noise_High_dataframe[\"target_10_val\"].apply(encode_target)\n",
        "Noise_Low_dataframe[\"target_10_val\"] = Noise_Low_dataframe[\"target_10_val\"].apply(encode_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_Jfvo6jBNw5"
      },
      "source": [
        "## Setting up Dataset & Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYmSaMKKBNw6"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, noise, transform=None, target_transform=None,target = None, drop = None):\n",
        "        self.dataframe = dataframe\n",
        "        if drop != None:\n",
        "            self.X = dataframe.drop(drop, axis=1).values\n",
        "        else:\n",
        "            self.X = dataframe.values\n",
        "        self.y = dataframe[target].values\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.noise = noise\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item, label = self.X[idx], self.y[idx]\n",
        "        return item, label\n",
        "\n",
        "    def get_noise(self):\n",
        "        return self.noise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUzwd5RYBNw6"
      },
      "outputs": [],
      "source": [
        "#Setting up datasets\n",
        "Noise_0_dataset = CustomDataset(Noise_0_dataframe, \"0\",drop = [\"row_num\",\"day\",\"era\",\"target_10_val\",\"target_5_val\"], target = \"era\")\n",
        "Noise_Low_dataset = CustomDataset(Noise_Low_dataframe, \"Low\", drop = [\"row_num\",\"day\",\"era\",\"target_10_val\",\"target_5_val\",\"data_type\"], target = \"target_10_val\")\n",
        "Noise_High_dataset = CustomDataset(Noise_High_dataframe, \"High\", drop = [\"row_num\",\"day\",\"era\",\"target_10_val\",\"target_5_val\",\"data_type\"], target = \"target_10_val\")\n",
        "Noise_0_train, Noise_0_test = random_split(Noise_0_dataset, [int(0.8 * len(Noise_0_dataset)), len(Noise_0_dataset) - int(0.8 * len(Noise_0_dataset))])\n",
        "Noise_Low_train, Noise_Low_test = random_split(Noise_Low_dataset, [int(0.8 * len(Noise_Low_dataset)), len(Noise_Low_dataset) - int(0.8 * len(Noise_Low_dataset))])\n",
        "Noise_High_train, Noise_High_test = random_split(Noise_High_dataset, [int(0.8 * len(Noise_High_dataset)), len(Noise_High_dataset) - int(0.8 * len(Noise_High_dataset))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2QH7ZDlBNw6"
      },
      "outputs": [],
      "source": [
        "#Setting up dataloaders\n",
        "Noise_0_train_loader = DataLoader(Noise_0_train, batch_size=64, shuffle=True)\n",
        "Noise_0_test_loader = DataLoader(Noise_0_test, batch_size=64, shuffle=True)\n",
        "Noise_Low_train_loader = DataLoader(Noise_Low_train, batch_size=256, shuffle=True)\n",
        "Noise_Low_test_loader = DataLoader(Noise_Low_test, batch_size=256, shuffle=True)\n",
        "Noise_High_train_loader = DataLoader(Noise_High_train, batch_size=64, shuffle=True)\n",
        "Noise_High_test_loader = DataLoader(Noise_High_test, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWFHHoWmBNw7"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zdu0tjhABNw7"
      },
      "outputs": [],
      "source": [
        "class MyMLP(torch.nn.Module):\n",
        "    def __init__ (self, modules):\n",
        "        super().__init__()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        MyModuleList = torch.nn.ModuleList([m for m in modules])\n",
        "        self.layers = torch.nn.Sequential(*MyModuleList)\n",
        "        self.softmax = torch.nn.Softmax(dim = 1)\n",
        "\n",
        "\n",
        "    def forward(self, X: torch.Tensor):\n",
        "        if (X.shape[1] != 24):\n",
        "            raise ValueError(\"Input shape must be (batch_size, 24)\")\n",
        "        X = X.to(device)\n",
        "        X = self.layers(X)\n",
        "        X = self.softmax(X)\n",
        "\n",
        "        return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWEVAs-7lFyR"
      },
      "outputs": [],
      "source": [
        "class EnsembleClassifier():\n",
        "  def __init__(self, Dataset, num_classifiers,sample_percentage = 0.8):\n",
        "    self.Dataset = Dataset\n",
        "    self.sample_percentage = sample_percentage\n",
        "    self.num_classifiers = num_classifiers\n",
        "    self.models = torch.nn.ModuleList()\n",
        "\n",
        "    #Currently hard coded the model, change later\n",
        "    for clf in range(num_classifiers):\n",
        "      self.models.append(MyMLP([torch.nn.Linear(24,64),torch.nn.ReLU(),torch.nn.Linear(64,256),torch.nn.Dropout(p = 0.2),torch.nn.ReLU(),torch.nn.Linear(256,64),torch.nn.Dropout(p = 0.2),torch.nn.ReLU(),torch.nn.Linear(64,12)]).to(device))\n",
        "\n",
        "  def train(self,criterion,batchsize,num_epochs):\n",
        "      num_samples = int(0.8 * len(self.Dataset))\n",
        "      indices = list(range(num_samples))\n",
        "      bootstrap_dataloaders = []\n",
        "      accuracy = torchmetrics.Accuracy(task = \"multiclass\",num_classes = 12).to(device)\n",
        "\n",
        "      for c in range(self.num_classifiers):\n",
        "          sampled_indices = torch.randperm(num_samples)[:int(num_samples * self.sample_percentage)]\n",
        "          sampler = SubsetRandomSampler(sampled_indices)\n",
        "          sampled_dataloader = DataLoader(self.Dataset, batch_size = batchsize, sampler=sampler)\n",
        "          bootstrap_dataloaders.append(sampled_dataloader)\n",
        "\n",
        "      for epoch in range(num_epochs):\n",
        "        print(\"Starting Epoch-\",epoch)\n",
        "        epoch_losses = torch.zeros(self.num_classifiers).to(device)\n",
        "        epoch_accuracies = torch.zeros(self.num_classifiers).to(device)\n",
        "        for model_num in range(len(self.models)):\n",
        "          optimizer = optim.Adam(self.models[model_num].parameters(), lr=0.0001, weight_decay=0.001)\n",
        "          self.models[model_num].train()\n",
        "          for inputs, labels in bootstrap_dataloaders[model_num]:\n",
        "            inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = self.models[model_num](inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_losses[model_num] += loss.item()\n",
        "            epoch_accuracies[model_num] += accuracy(outputs, labels)\n",
        "\n",
        "          epoch_losses[model_num] /= len(bootstrap_dataloaders[model_num])\n",
        "          epoch_accuracies[model_num] /= len(bootstrap_dataloaders[model_num])\n",
        "          print(f\"Classifier {model_num}: Loss = {epoch_losses[model_num]:.4f}, Accuracy = {epoch_accuracies[model_num]:.4f}\")\n",
        "\n",
        "  def forward(self, x):\n",
        "    ensemble_predictions = torch.zeros(x.size(0), 12, device=device)\n",
        "    for model_num in range(len(self.models)):\n",
        "      self.models[model_num].eval()\n",
        "      outputs = self.models[model_num](x)\n",
        "      ensemble_predictions += outputs\n",
        "    ensemble_predictions /= self.num_classifiers\n",
        "    return ensemble_predictions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KOB_XCYweg7",
        "outputId": "ecba5d07-6610-4f93-b91d-431a8a8a7446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier 4: Loss = 1.9261, Accuracy = 0.7007\n",
            "Starting Epoch- 5\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m Ensemble \u001b[38;5;241m=\u001b[39m EnsembleClassifier(Noise_Low_dataset,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m0.7\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mEnsemble\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[16], line 31\u001b[0m, in \u001b[0;36mEnsembleClassifier.train\u001b[1;34m(self, criterion, batchsize, num_epochs)\u001b[0m\n\u001b[0;32m     29\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[model_num]\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels[model_num]\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 31\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbootstrap_dataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_num\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m  \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m  \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Anaconda\\envs\\amlenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32mc:\\Anaconda\\envs\\amlenv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32mc:\\Anaconda\\envs\\amlenv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32mc:\\Anaconda\\envs\\amlenv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "Ensemble = EnsembleClassifier(Noise_Low_dataset,5,0.7)\n",
        "Ensemble.train(torch.nn.CrossEntropyLoss(),128,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "hFlXfShY7Bee",
        "outputId": "fa58e9f2-0840-4635-9970-486e08ec30b4"
      },
      "outputs": [],
      "source": [
        "for input,label in Noise_Low_test_loader:\n",
        "  input, label = input.to(device).to(torch.float32), label.to(device).to(torch.long)\n",
        "  outputs = Ensemble.forward(input)\n",
        "  predicted_labels = torch.argmax(outputs, dim=1)\n",
        "  print((predicted_labels == label).sum()/256)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgsVEXEjT7ub"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10,verbose=True):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "    model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_train_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_train_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = running_train_loss / len(train_loader)\n",
        "        train_accuracy = correct_train / total_train\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device).to(torch.float32), labels.to(device).to(torch.long)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                running_val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total_val += labels.size(0)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = running_val_loss / len(val_loader)\n",
        "        val_accuracy = correct_val / total_val\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, '\n",
        "              f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(range(1, num_epochs + 1), train_losses, label='Train')\n",
        "    plt.plot(range(1, num_epochs + 1), val_losses, label='Validation')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train')\n",
        "    plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RSMHnpcvT7uc",
        "outputId": "c4e8a53f-fc01-4581-8888-5bf5de246367"
      },
      "outputs": [],
      "source": [
        "Model = MyMLP([torch.nn.Linear(24,64),torch.nn.ReLU(),torch.nn.Linear(64,128),torch.nn.Dropout(p = 0.2),torch.nn.ReLU(),torch.nn.Linear(128,64),torch.nn.Dropout(p = 0.2),torch.nn.ReLU(),torch.nn.Linear(64,5)]).to(device)\n",
        "optimizer = optim.Adam(Model.parameters(), lr=0.001, weight_decay=0.001)\n",
        "train_model(Model,torch.nn.CrossEntropyLoss(), optimizer,Noise_High_train_loader, Noise_High_test_loader,num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiFVifQGT7uc"
      },
      "outputs": [],
      "source": [
        "PATH = \"model.pt\"\n",
        "torch.save(Model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38o5IWpRT7uc",
        "outputId": "721d6010-3b0b-4d06-9570-0e22d7b11463"
      },
      "outputs": [],
      "source": [
        "PATH = \"model.pt\"\n",
        "Model.load_state_dict(torch.load(PATH))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "0.0.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c0de4b95e4545c0bbe9eafea153125b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd0232e4017240debb92efe3100b71a3",
              "IPY_MODEL_32fad7dacf594cb488bf6a261f933f8b",
              "IPY_MODEL_613424989e984c8888528d3a4d61a318"
            ],
            "layout": "IPY_MODEL_1ab03e476b624c699cc85fb8d9ec71a1"
          }
        },
        "1ab03e476b624c699cc85fb8d9ec71a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "2a39fbb734d74e8b9b9f44a0627b35a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32fad7dacf594cb488bf6a261f933f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2d642748e7c4d81a2ab1ec8d9720926",
            "max": 98,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5217d52572ba41ceba0130b5ac47af5b",
            "value": 98
          }
        },
        "3e901c104db34d8a88a632d8d897022b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5217d52572ba41ceba0130b5ac47af5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "613424989e984c8888528d3a4d61a318": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a39fbb734d74e8b9b9f44a0627b35a2",
            "placeholder": "​",
            "style": "IPY_MODEL_abbe93dc21094598aa884f59e3b4aaab",
            "value": " 98/98 [00:00&lt;00:00, 280.28it/s, v_num=3]"
          }
        },
        "95bf24f9ca0b4baab139e7716dffb754": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d642748e7c4d81a2ab1ec8d9720926": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abbe93dc21094598aa884f59e3b4aaab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd0232e4017240debb92efe3100b71a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95bf24f9ca0b4baab139e7716dffb754",
            "placeholder": "​",
            "style": "IPY_MODEL_3e901c104db34d8a88a632d8d897022b",
            "value": "Epoch 9: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
