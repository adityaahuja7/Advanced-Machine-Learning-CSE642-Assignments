{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "from tabpfn import TabPFNClassifier\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, noise, transform=None, target_transform=None, drop=None, target=None):\n",
    "        self.dataframe = dataframe\n",
    "        if drop != None:\n",
    "            self.X = dataframe.drop(drop, axis=1).values\n",
    "        else:\n",
    "            self.X = dataframe.values\n",
    "        \n",
    "        self.y = dataframe[target].values\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.noise = noise\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item, label = self.X[idx], self.y[idx]\n",
    "        return item, label\n",
    "\n",
    "    def get_noise(self):\n",
    "        return self.noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Noise_0_dataframe = pd.read_csv(\"../Data/Assignment1/data_0_noise\")\n",
    "Noise_Low_dataframe = pd.read_csv(\"../Data/Assignment1/data_Low_noise\")\n",
    "Noise_High_dataframe = pd.read_csv(\"../Data/Assignment1/data_High_noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_index = list(Noise_0_dataframe[\"era\"].unique())\n",
    "class_index_noise = list(Noise_Low_dataframe[\"era\"].unique())\n",
    "class_index_t10v_noise = list(Noise_Low_dataframe[\"target_10_val\"].unique())\n",
    "\n",
    "def encode(value, class_index = class_index):\n",
    "    return class_index.index(value)\n",
    "\n",
    "def encode_noise(value, class_index = class_index_noise):\n",
    "    return class_index.index(value)\n",
    "\n",
    "def encode_noise_t10v(value, class_index = class_index_t10v_noise):\n",
    "    return class_index.index(value)\n",
    "\n",
    "\n",
    "Noise_0_dataframe[\"era\"] = Noise_0_dataframe[\"era\"].apply(encode)\n",
    "Noise_Low_dataframe[\"era\"] = Noise_Low_dataframe[\"era\"].apply(encode_noise)\n",
    "Noise_High_dataframe[\"era\"] = Noise_High_dataframe[\"era\"].apply(encode_noise)\n",
    "Noise_Low_dataframe[\"target_10_val\"] = Noise_Low_dataframe[\"target_10_val\"].apply(encode_noise_t10v)\n",
    "Noise_High_dataframe[\"target_10_val\"] = Noise_High_dataframe[\"target_10_val\"].apply(encode_noise_t10v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Noise_0_dataset_era = CustomDataset(Noise_0_dataframe, \"0\",drop = [\"row_num\",\"day\",\"era\",\"target_10_val\",\"target_5_val\"], target = \"era\")\n",
    "Noise_Low_dataset_era = CustomDataset(Noise_Low_dataframe, \"Low\", drop = [\"row_num\",\"day\",\"era\",\"target_10_val\",\"target_5_val\",\"data_type\"], target = \"era\")\n",
    "Noise_High_dataset_era = CustomDataset(Noise_High_dataframe, \"High\", drop = [\"row_num\",\"day\",\"era\",\"target_10_val\",\"target_5_val\",\"data_type\"], target = \"era\")\n",
    "Noise_Low_dataset_t10v = CustomDataset(Noise_Low_dataframe, \"Low\", drop = [\"row_num\",\"day\",\"era\",\"target_10_val\",\"target_5_val\",\"data_type\"], target = \"target_10_val\")\n",
    "Noise_High_dataset_t10v = CustomDataset(Noise_High_dataframe, \"High\", drop = [\"row_num\",\"day\",\"era\",\"target_10_val\",\"target_5_val\",\"data_type\"], target = \"target_10_val\")\n",
    "Noise_0_train_era, Noise_0_test_era = random_split(Noise_0_dataset_era, [int(len(Noise_0_dataset_era)*0.8), int(len(Noise_0_dataset_era)*0.2)])\n",
    "Noise_Low_train_era, Noise_Low_test_era = random_split(Noise_Low_dataset_era, [int(len(Noise_Low_dataset_era)*0.8), int(len(Noise_Low_dataset_era)*0.2)])\n",
    "Noise_High_train_era, Noise_High_test_era = random_split(Noise_High_dataset_era, [int(len(Noise_High_dataset_era)*0.8), int(len(Noise_High_dataset_era)*0.2)])\n",
    "Noise_Low_train_t10v, Noise_Low_test_t10v = random_split(Noise_Low_dataset_t10v, [int(len(Noise_Low_dataset_t10v)*0.8), int(len(Noise_Low_dataset_t10v)*0.2)])\n",
    "Noise_High_train_t10v, Noise_High_test_t10v = random_split(Noise_High_dataset_t10v, [int(len(Noise_High_dataset_t10v)*0.8), int(len(Noise_High_dataset_t10v)*0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up dataloaders\n",
    "Noise_0_era_train_loader = DataLoader(Noise_0_train_era, batch_size=512, shuffle=True)\n",
    "Noise_0_era_test_loader = DataLoader(Noise_0_test_era, batch_size=512, shuffle=True)\n",
    "########################################################################################\n",
    "Noise_Low_era_train_loader = DataLoader(Noise_Low_train_era, batch_size=512, shuffle=True)\n",
    "Noise_Low_era_test_loader = DataLoader(Noise_Low_test_era, batch_size=512, shuffle=True)\n",
    "########################################################################################\n",
    "Noise_High_era_train_loader = DataLoader(Noise_High_train_era, batch_size=512, shuffle=True)\n",
    "Noise_High_era_test_loader = DataLoader(Noise_High_test_era, batch_size=512, shuffle=True)\n",
    "########################################################################################\n",
    "Noise_Low_t10v_train_loader = DataLoader(Noise_Low_train_t10v, batch_size=1000, shuffle=True)\n",
    "Noise_Low_t10v_test_loader = DataLoader(Noise_Low_test_t10v, batch_size=512, shuffle=True)\n",
    "########################################################################################\n",
    "Noise_High_t10v_train_loader = DataLoader(Noise_High_train_t10v, batch_size=1000, shuffle=True)\n",
    "Noise_High_t10v_test_loader = DataLoader(Noise_High_test_t10v, batch_size=512, shuffle=True)\n",
    "########################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicition_assembler(predictions,probabilities):\n",
    "    final_winner=[]\n",
    "    no_of_models=len(predictions)\n",
    "    batch_size=len(predictions[0])\n",
    "    for i in range(batch_size):\n",
    "        winner_dict={}\n",
    "        for j in range(no_of_models):\n",
    "            if predictions[j][i] not in winner_dict.keys():\n",
    "                winner_dict[predictions[j][i]]=0\n",
    "            winner_dict[predictions[j][i]]+=probabilities[j][i]\n",
    "        final_winner.append(max(winner_dict,key=winner_dict.get))\n",
    "    return final_winner\n",
    "\n",
    "def fit_test_tabpfn(train_dataloader,test_dataloader,no_of_models_to_ensemble=1,ensemble_config=1):\n",
    "    all_tabpfns=[]\n",
    "    for data,target in tqdm(train_dataloader, desc=\"FITTING\"):\n",
    "        classifier = TabPFNClassifier(device=device, N_ensemble_configurations=ensemble_config)\n",
    "        classifier.fit(data,target)\n",
    "        all_tabpfns.append(classifier)\n",
    "\n",
    "    total=0\n",
    "    correct=0\n",
    "    for data,target in tqdm(test_dataloader, desc=\"TESTING\"):\n",
    "        each_model_prob=[]\n",
    "        each_model_pred=[]\n",
    "        random_models = random.sample(all_tabpfns, no_of_models_to_ensemble)\n",
    "        for model in random_models:\n",
    "            y_pred,p_pred=model.predict(data,return_winning_probability=True)\n",
    "            each_model_prob.append(p_pred)\n",
    "            each_model_pred.append(y_pred)\n",
    "        y_pred_summ=predicition_assembler(each_model_pred,each_model_prob)\n",
    "        total+=len(y_pred_summ)\n",
    "        correct+=sum(1 for p, t in zip(y_pred_summ, target) if p == t)\n",
    "    print(f\"Accuracy: {correct/total:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FITTING: 100%|██████████| 250/250 [00:02<00:00, 98.02it/s] \n",
      "TESTING: 100%|██████████| 122/122 [13:20<00:00,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fit_test_tabpfn(train_dataloader=Noise_Low_t10v_train_loader,test_dataloader=Noise_Low_t10v_test_loader,no_of_models_to_ensemble=10,ensemble_config=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FITTING: 100%|██████████| 200/200 [00:01<00:00, 101.23it/s]\n",
      "TESTING: 100%|██████████| 98/98 [07:51<00:00,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fit_test_tabpfn(train_dataloader=Noise_High_t10v_train_loader,test_dataloader=Noise_High_t10v_test_loader,no_of_models_to_ensemble=10,ensemble_config=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
